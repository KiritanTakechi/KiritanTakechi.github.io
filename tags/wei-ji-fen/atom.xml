<?xml version="1.0" encoding="UTF-8"?>
<feed xmlns="http://www.w3.org/2005/Atom" xml:lang="zh">
    <title>雪間 - 微积分</title>
    <subtitle>Kiritan&#x27;s Blog</subtitle>
    <link rel="self" type="application/atom+xml" href="https://kiritantakechi.github.io/tags/wei-ji-fen/atom.xml"/>
    <link rel="alternate" type="text/html" href="https://kiritantakechi.github.io"/>
    <generator uri="https://www.getzola.org/">Zola</generator>
    <updated>2025-06-28T00:25:00+08:00</updated>
    <id>https://kiritantakechi.github.io/tags/wei-ji-fen/atom.xml</id>
    <entry xml:lang="zh">
        <title>矩阵求导公式推导</title>
        <published>2025-06-27T22:00:29+08:00</published>
        <updated>2025-06-28T00:25:00+08:00</updated>
        
        <author>
          <name>
            
              Unknown
            
          </name>
        </author>
        
        <link rel="alternate" type="text/html" href="https://kiritantakechi.github.io/blog/matrix-calculus-proofs/"/>
        <id>https://kiritantakechi.github.io/blog/matrix-calculus-proofs/</id>
        
        <content type="html" xml:base="https://kiritantakechi.github.io/blog/matrix-calculus-proofs/">&lt;p&gt;本文旨在从最基础的导数定义出发，一步步证明那些最常用、最重要的矩阵求导公式。&lt;&#x2F;p&gt;
&lt;h1 id=&quot;1-he-xin-ding-yi&quot;&gt;1. 核心定义&lt;&#x2F;h1&gt;
&lt;p&gt;所有证明都将回归到导数的基本定义。&lt;&#x2F;p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;标量对向量的导数（梯度）&lt;&#x2F;strong&gt;：对于一个标量函数 $f(x)$ 和一个列向量 $x \in \mathbb{R}^n$，其梯度 $\nabla_x f(x)$ 是一个列向量，其第 $k$ 个元素是 $f$ 对 $x$ 第 $k$ 个分量 $x_k$ 的偏导数。

&lt;div class=&quot;math-block&quot;&gt;
$$
\nabla_x f(x) = \frac{\partial f}{\partial x} = \begin{pmatrix} \frac{\partial f}{\partial x_1} \\ \frac{\partial f}{\partial x_2} \\ \vdots \\ \frac{\partial f}{\partial x_n} \end{pmatrix}
$$
&lt;&#x2F;div&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;&lt;strong&gt;标量对矩阵的导数&lt;&#x2F;strong&gt;：对于一个标量函数 $f(X)$ 和一个 $m \times n$ 的矩阵 $X$，其导数是一个与 $X$ 形状相同的矩阵，其 $(k, l)$ 位置的元素是 $f$ 对 $X_{kl}$ 的偏导数。

&lt;div class=&quot;math-block&quot;&gt;
$$
\left( \frac{\partial f}{\partial X} \right)_{kl} = \frac{\partial f}{\partial X_{kl}}
$$
&lt;&#x2F;div&gt;

我们将始终围绕这两个定义展开推导。&lt;&#x2F;li&gt;
&lt;&#x2F;ol&gt;
&lt;h1 id=&quot;2-biao-liang-dui-xiang-liang-qiu-dao-scalar-by-vector&quot;&gt;2. 标量对向量求导 (Scalar-by-Vector)&lt;&#x2F;h1&gt;
&lt;h2 id=&quot;1-xian-xing-xing-shi-nabla-x-a-t-x-a&quot;&gt;1) 线性形式：$\nabla_x (a^T x) = a$&lt;&#x2F;h2&gt;
&lt;p&gt;&lt;strong&gt;证明&lt;&#x2F;strong&gt;：&lt;&#x2F;p&gt;
&lt;p&gt;设函数 $f(x) = a^T x$，其中 $a$ 和 $x$ 都是 $n \times 1$ 的列向量。我们将 $f(x)$ 展开为求和形式：

&lt;div class=&quot;math-block&quot;&gt;
$$
f(x) = a^T x = \sum_{i=1}^{n} a_i x_i = a_1 x_1 + a_2 x_2 + \dots + a_n x_n
$$
&lt;&#x2F;div&gt;

计算 $f(x)$ 对 $x$ 的任意分量 $x_k$ 的偏导数：

&lt;div class=&quot;math-block&quot;&gt;
$$
\frac{\partial f}{\partial x_k} = \frac{\partial}{\partial x_k} \left( \sum_{i=1}^{n} a_i x_i \right) = a_k
$$
&lt;&#x2F;div&gt;

这意味着梯度的第 $k$ 个分量就是 $a_k$。我们将所有分量组合回梯度向量中：

&lt;div class=&quot;math-block&quot;&gt;
$$
\nabla_x f(x) = \begin{pmatrix} a_1 \\ a_2 \\ \vdots \\ a_n \end{pmatrix} = a
$$
&lt;&#x2F;div&gt;

&lt;strong&gt;证毕。&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;h2 id=&quot;2-ji-chu-er-ci-xing-nabla-x-x-t-x-2x&quot;&gt;2) 基础二次型：$\nabla_x (x^T x) = 2x$&lt;&#x2F;h2&gt;
&lt;p&gt;&lt;strong&gt;证明&lt;&#x2F;strong&gt;：&lt;&#x2F;p&gt;
&lt;p&gt;设函数 $f(x) = x^T x$。我们可以将其展开为分量的平方和：

&lt;div class=&quot;math-block&quot;&gt;
$$
f(x) = x^T x = \sum_{i=1}^{n} x_i^2 = x_1^2 + x_2^2 + \dots + x_n^2
$$
&lt;&#x2F;div&gt;

计算 $f(x)$ 对 $x$ 的任意分量 $x_k$ 的偏导数：

&lt;div class=&quot;math-block&quot;&gt;
$$
\frac{\partial f}{\partial x_k} = \frac{\partial}{\partial x_k} \left( \sum_{i=1}^{n} x_i^2 \right) = \frac{\partial}{\partial x_k} (x_k^2) = 2x_k
$$
&lt;&#x2F;div&gt;

梯度的第 $k$ 个分量是 $2x_k$。我们将所有分量组合回梯度向量：

&lt;div class=&quot;math-block&quot;&gt;
$$
\nabla_x f(x) = \begin{pmatrix} 2x_1 \\ 2x_2 \\ \vdots \\ 2x_n \end{pmatrix} = 2x
$$
&lt;&#x2F;div&gt;

&lt;strong&gt;证毕。&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;h2 id=&quot;3-tong-yong-er-ci-xing-nabla-x-x-t-a-x-a-a-t-x&quot;&gt;3) 通用二次型：$\nabla_x (x^T A x) = (A + A^T)x$&lt;&#x2F;h2&gt;
&lt;p&gt;&lt;strong&gt;证明&lt;&#x2F;strong&gt;：&lt;&#x2F;p&gt;
&lt;p&gt;设函数 $f(x) = x^T A x$，其中 $A$ 是一个 $n \times n$ 的矩阵。我们可以将其展开为二次型求和形式：

&lt;div class=&quot;math-block&quot;&gt;
$$
f(x) = x^T A x = \sum_{i=1}^{n} \sum_{j=1}^{n} A_{ij} x_i x_j
$$
&lt;&#x2F;div&gt;

我们计算 $f(x)$ 对 $x$ 的任意分量 $x_k$ 的偏导数。为了清晰地分析，我们将双重求和中与 $x_k$ 相关的项（即 $i=k$ 或 $j=k$ 的项）分离出来。&lt;&#x2F;p&gt;
&lt;p&gt;这个和式可以被分解为四部分：&lt;&#x2F;p&gt;
&lt;ol&gt;
&lt;li&gt;$i=k$ 且 $j=k$ 的项：$A_{kk}x_k^2$&lt;&#x2F;li&gt;
&lt;li&gt;$i=k$ 但 $j \neq k$ 的项：$\sum_{j \neq k} A_{kj} x_k x_j$&lt;&#x2F;li&gt;
&lt;li&gt;$j=k$ 但 $i \neq k$ 的项：$\sum_{i \neq k} A_{ik} x_i x_k$&lt;&#x2F;li&gt;
&lt;li&gt;$i \neq k$ 且 $j \neq k$ 的项：$\sum_{i \neq k} \sum_{j \neq k} A_{ij} x_i x_j$&lt;&#x2F;li&gt;
&lt;&#x2F;ol&gt;
&lt;p&gt;现在我们对 $f(x)$ 关于 $x_k$ 求偏导。只有前三部分包含 $x_k$，第四部分导数为零。

&lt;div class=&quot;math-block&quot;&gt;
$$
\frac{\partial f}{\partial x_k} = \frac{\partial}{\partial x_k} \left( A_{kk}x_k^2 + \sum_{j \neq k} A_{kj} x_k x_j + \sum_{i \neq k} A_{ik} x_i x_k \right)
$$
&lt;&#x2F;div&gt;

分别对三项求导：&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;$\frac{\partial}{\partial x_k}(A_{kk}x_k^2) = 2A_{kk}x_k$&lt;&#x2F;li&gt;
&lt;li&gt;$\frac{\partial}{\partial x_k}(\sum_{j \neq k} A_{kj} x_k x_j) = \sum_{j \neq k} A_{kj} x_j$&lt;&#x2F;li&gt;
&lt;li&gt;$\frac{\partial}{\partial x_k}(\sum_{i \neq k} A_{ik} x_i x_k) = \sum_{i \neq k} A_{ik} x_i$&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;将它们加起来：

&lt;div class=&quot;math-block&quot;&gt;
$$
\frac{\partial f}{\partial x_k} = 2A_{kk}x_k + \sum_{j \neq k} A_{kj} x_j + \sum_{i \neq k} A_{ik} x_i
$$
&lt;&#x2F;div&gt;

现在我们进行一个巧妙的重组，把 $2A_{kk}x_k$ 分成两部分：

&lt;div class=&quot;math-block&quot;&gt;
$$
\frac{\partial f}{\partial x_k} = \left( A_{kk}x_k + \sum_{j \neq k} A_{kj} x_j \right) + \left( A_{kk}x_k + \sum_{i \neq k} A_{ik} x_i \right)
$$
&lt;&#x2F;div&gt;

观察括号内的两项：&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;第一项是：$\sum_{j = 1}^{n} A_{kj} x_j$。这正是矩阵向量乘积 $Ax$ 的第 $k$ 个元素，记为 $(Ax)_k$。&lt;&#x2F;li&gt;
&lt;li&gt;第二项是：$\sum_{i = 1}^{n} A_{ik} x_i$。这可以被看作是 $A$ 的第 $k$ 列与 $x$ 的点积，也就是 $A^T$ 的第 $k$ 行与 $x$ 的点积。这正是矩阵向量乘积 $A^Tx$ 的第 $k$ 个元素，记为 $(A^Tx)_k$。&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;所以，梯度的第 $k$ 个分量是：

&lt;div class=&quot;math-block&quot;&gt;
$$
\frac{\partial f}{\partial x_k} = (Ax)_k + (A^Tx)_k = ((A + A^T)x)_k
$$
&lt;&#x2F;div&gt;

将所有分量组合回梯度向量，我们得到：

&lt;div class=&quot;math-block&quot;&gt;
$$
\nabla_x f(x) = (A + A^T)x
$$
&lt;&#x2F;div&gt;

&lt;strong&gt;证毕。&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;h1 id=&quot;3-biao-liang-dui-ju-zhen-qiu-dao-scalar-by-matrix&quot;&gt;3. 标量对矩阵求导 (Scalar-by-Matrix)&lt;&#x2F;h1&gt;
&lt;p&gt;在掌握了对向量的求导后，我们自然地将这一思想扩展到矩阵。&lt;&#x2F;p&gt;
&lt;h3 id=&quot;1-ji-han-shu-xing-shi-frac-partial-partial-x-text-tr-ax-a-t&quot;&gt;1) 迹函数形式：$\frac{\partial}{\partial X} \text{tr}(AX) = A^T$&lt;&#x2F;h3&gt;
&lt;p&gt;&lt;strong&gt;证明&lt;&#x2F;strong&gt;：&lt;&#x2F;p&gt;
&lt;p&gt;设函数 $f(X) = \text{tr}(AX)$。其中 $A$ 是 $m \times n$ 矩阵，$X$ 是 $n \times m$ 矩阵。其乘积 $AX$ 是 $m \times m$ 方阵。我们将迹的表达式用求和形式写出：

&lt;div class=&quot;math-block&quot;&gt;
$$
f(X) = \text{tr}(AX) = \sum_{i=1}^{m} (AX)_{ii} = \sum_{i=1}^{m} \sum_{j=1}^{n} A_{ij} X_{ji}
$$
&lt;&#x2F;div&gt;

我们计算 $f(X)$ 对 $X$ 的任意一个元素 $X_{kl}$ 的偏导数：

&lt;div class=&quot;math-block&quot;&gt;
$$
\frac{\partial f}{\partial X_{kl}} = \frac{\partial}{\partial X_{kl}} \left( \sum_{i=1}^{m} \sum_{j=1}^{n} A_{ij} X_{ji} \right)
$$
&lt;&#x2F;div&gt;

在所有项中，只有当 $X$ 的索引 $(j, i)$ 等于 $(k, l)$ 时，导数才不为零。因此，只有 $A_{lk} X_{kl}$ 这一项对求导有贡献。

&lt;div class=&quot;math-block&quot;&gt;
$$
\frac{\partial f}{\partial X_{kl}} = A_{lk}
$$
&lt;&#x2F;div&gt;

这意味着导数矩阵在 $(k, l)$ 位置的元素是 $A_{lk}$。根据矩阵转置的定义，我们得到：

&lt;div class=&quot;math-block&quot;&gt;
$$
\frac{\partial f}{\partial X} = A^T
$$
&lt;&#x2F;div&gt;

&lt;strong&gt;证毕。&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;h2 id=&quot;2-xing-lie-shi-xing-shi-frac-partial-partial-x-det-x-det-x-x-1-t&quot;&gt;2) 行列式形式：$\frac{\partial}{\partial X} \det(X) = \det(X)(X^{-1})^T$&lt;&#x2F;h2&gt;
&lt;p&gt;&lt;strong&gt;证明&lt;&#x2F;strong&gt;：&lt;&#x2F;p&gt;
&lt;p&gt;这个证明需要用到行列式的&lt;strong&gt;拉普拉斯展开&lt;&#x2F;strong&gt;。设 $f(X) = \det(X)$，其中 $X$ 是 $n \times n$ 方阵。我们将行列式沿第 $k$ 行展开：

&lt;div class=&quot;math-block&quot;&gt;
$$
f(X) = \det(X) = \sum_{j=1}^{n} X_{kj} C_{kj}
$$
&lt;&#x2F;div&gt;

其中 $C_{kj}$ 是元素 $X_{kj}$ 的代数余子式，其值不依赖于 $X_{kj}$。我们对 $X$ 的任意元素 $X_{kl}$ 求偏导：

&lt;div class=&quot;math-block&quot;&gt;
$$
\frac{\partial f}{\partial X_{kl}} = \frac{\partial}{\partial X_{kl}} \left( \sum_{j=1}^{n} X_{kj} C_{kj} \right) = C_{kl}
$$
&lt;&#x2F;div&gt;

因此，导数矩阵就是 $X$ 的代数余子式矩阵 $C$。

&lt;div class=&quot;math-block&quot;&gt;
$$
\frac{\partial f}{\partial X} = C
$$
&lt;&#x2F;div&gt;

根据伴随矩阵求逆的公式 $X^{-1} = \frac{1}{\det(X)} \text{adj}(X)$，以及伴随矩阵是代数余子式矩阵的转置 $\text{adj}(X) = C^T$，我们有：

&lt;div class=&quot;math-block&quot;&gt;
$$
C^T = \det(X) X^{-1}
$$
&lt;&#x2F;div&gt;

对两边取转置，得到 $C = \det(X) (X^{-1})^T$。所以：

&lt;div class=&quot;math-block&quot;&gt;
$$
\frac{\partial f}{\partial X} = \det(X) (X^{-1})^T
$$
&lt;&#x2F;div&gt;

&lt;strong&gt;证毕。&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;h2 id=&quot;3-dui-shu-xing-lie-shi-xing-shi-frac-partial-partial-x-log-det-x-x-1-t&quot;&gt;3) 对数行列式形式：$\frac{\partial}{\partial X} \log(\det(X)) = (X^{-1})^T$&lt;&#x2F;h2&gt;
&lt;p&gt;&lt;strong&gt;证明&lt;&#x2F;strong&gt;：&lt;&#x2F;p&gt;
&lt;p&gt;这是一个链式法则的直接应用。设 $f(X) = \log(\det(X))$，并令 $u = \det(X)$。
根据链式法则：

&lt;div class=&quot;math-block&quot;&gt;
$$
\frac{\partial f}{\partial X} = \frac{df}{du} \cdot \frac{\partial u}{\partial X}
$$
&lt;&#x2F;div&gt;

我们知道 $\frac{df}{du} = \frac{1}{u} = \frac{1}{\det(X)}$，并从上一个证明中知道 $\frac{\partial u}{\partial X} = \det(X)(X^{-1})^T$。
代入得：

&lt;div class=&quot;math-block&quot;&gt;
$$
\frac{\partial f}{\partial X} = \frac{1}{\det(X)} \left( \det(X)(X^{-1})^T \right) = (X^{-1})^T
$$
&lt;&#x2F;div&gt;

&lt;strong&gt;证毕。&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;h1 id=&quot;4-jie-lun&quot;&gt;4. 结论&lt;&#x2F;h1&gt;
&lt;p&gt;通过从最基本的偏导数定义出发，我们能够严谨地推导出矩阵求导中的一系列核心公式。理解这些推导过程，不仅能帮助我们记忆公式，更重要的是建立了处理更复杂向量和矩阵函数求导问题的坚实基础。&lt;&#x2F;p&gt;
</content>
        
    </entry>
</feed>
